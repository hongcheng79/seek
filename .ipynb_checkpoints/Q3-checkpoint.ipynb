{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import inflection\n",
    "import boto3\n",
    "import unittest\n",
    "import os\n",
    "\n",
    "# config\n",
    "data_path = '/home/chc/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "question3_data_path = data_path + '/jobposts'\n",
    "question3_data_file = question3_data_path +'/data job posts.csv'\n",
    "\n",
    "if not os.path.exists(question3_data_path):\n",
    "    os.mkdir(question3_data_path)\n",
    "\n",
    "if not os.path.exists(question3_data_file):\n",
    "    print('Downloading data as '+question3_data_file)\n",
    "    os.system('cd '+question3_data_path+';kg dataset -o madhab -d jobposts')\n",
    "else:\n",
    "    print('Data file exist '+question3_data_file)\n",
    "    \n",
    "# Some issue with the csv file as is in zip format but the extension was wrong\n",
    "# Have to manually change it as zip and run unzip command\n",
    "    \n",
    "# Load data up\n",
    "question3_data = pd.read_csv(question3_data_file)\n",
    "question3_data.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Extract the following fields from the jobpost column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_b = pd.DataFrame()\n",
    "section_b['Company'] = question3_data['Company']\n",
    "section_b['Job Title'] = question3_data['jobpost'].str.extract('(TITLE:\\s{1,}.*\\w)', expand=False).str.replace('(TITLE:\\s{1,})','')\n",
    "section_b['Position Duration'] = question3_data['jobpost'].str.extract('(DURATION:\\s{1,}.*\\w)', expand=False).str.replace('(DURATION:\\s{1,})','')\n",
    "section_b['Position Location'] = question3_data['jobpost'].str.extract('(LOCATION:\\s{1,}.*\\w)', expand=False).str.replace('(LOCATION:\\s{1,})','')\n",
    "section_b['Job Description'] = question3_data['jobpost'].str.extract('(DESCRIPTION:\\s{1,}.*\\w)', expand=False).str.replace('(DESCRIPTION:\\s{1,})','')\n",
    "section_b['Job Responsibilities'] = question3_data['jobpost'].str.extract('(RESPONSIBILITIES:\\s{1,}.*\\w)', expand=False).str.replace('(RESPONSIBILITIES:\\s{1,})','')\n",
    "section_b['Required Qualifications'] = question3_data['jobpost'].str.extract('(QUALIFICATIONS:\\s{1,}.*\\w)', expand=False).str.replace('(QUALIFICATIONS:\\s{1,})','')\n",
    "section_b['Remuneration'] = question3_data['jobpost'].str.extract('(REMUNERATION:\\s{1,}.*\\w)', expand=False).str.replace('(REMUNERATION:\\s{1,})','')\n",
    "section_b['Application Deadline'] = question3_data['jobpost'].str.extract('(DEADLINE:\\s{1,}.*\\w)', expand=False).str.replace('(DEADLINE:\\s{1,})','')\n",
    "section_b['About Company'] = question3_data['jobpost'].str.extract('(COMPANY:\\s{1,}.*\\w)', expand=False).str.replace('(COMPANY:\\s{1,})','')\n",
    "section_b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Identify the company with the most number of job ads in the past 2 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question3_data.groupby('Company')['jobpost'].agg('count').idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Identify the month with the largest number of job ads over the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToTime(x):\n",
    "    if type(x) == pd.Timestamp:\n",
    "        return x.strftime('%Y%m')\n",
    "    else:\n",
    "        return '-'\n",
    "\n",
    "section_d = pd.DataFrame()\n",
    "section_d['Company'] = question3_data['Company']\n",
    "# Format is as YearMonth as we will consider year as well besides month\n",
    "section_d['Month Year'] = pd.to_datetime(question3_data['date'],format='%b %d, %Y',errors='coerce').map \\\n",
    "                            (lambda x: convertToTime(x))\n",
    "# Remove unknown date format that doesn't have year - eg Jun 1 10:13 PM\n",
    "section_d = section_d[section_d['Month Year'] != '-']\n",
    "    \n",
    "section_d.groupby(['Company','Month Year'])['Month Year'].agg('count').idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Clean text and generate new text from Job Responsibilities column: The new text\n",
    "shall not contain any stop words, and the plural words shall be converted into\n",
    "singular words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def custom_stop(text):    \n",
    "    if pd.isnull(text):\n",
    "        return ''\n",
    "    else:\n",
    "        return ' '.join([word for word in text.split() if word not in (stop)])\n",
    "\n",
    "def custom_singularize(text):\n",
    "    if pd.isnull(text):\n",
    "        return ''\n",
    "    else:\n",
    "        return inflection.singularize(text)\n",
    "    \n",
    "\n",
    "remove_stop_words = lambda r:[[word for word in word_tokenize(sente) if word not in stop_words] for sente in sent_tokenize(r)]\n",
    "\n",
    "section_b['Job Responsibilities'] = section_b['Job Responsibilities'].apply(custom_stop)\n",
    "section_b['Job Responsibilities'] = section_b['Job Responsibilities'].apply(custom_singularize)\n",
    "\n",
    "section_b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Write functions to identify null/NA values and to replace null/NA values with a\n",
    "custom message in “Duration” column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_b['Duration'] = section_b['Position Duration']\n",
    "section_b['Duration'].fillna('-', inplace=True)\n",
    "section_b.isnull().sum()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Store the results in a new Dataframe/SQL table(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_g = section_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) Write the results to an S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "filename = 'q3_upload.csv'\n",
    "bucket_name = 'seek'\n",
    "\n",
    "# Write to file\n",
    "section_g.to_csv(data_path+'/'+filename, index=False)\n",
    "\n",
    "# S3 upload\n",
    "s3.upload_file(data_path+'/'+filename, bucket_name, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
